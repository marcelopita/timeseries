
import java.util.ArrayList;
import java.util.Random;
import java.awt.geom.QuadCurve2D;
import java.io.File;
import java.io.ObjectInputStream.GetField;
import java.math.*;

import java.util.*;

class Neuron {
	int layerId;
	double weightsPreviousLayer[][];
	double net;
	double fnet;
	double f_derivate_net;
	double sensibility;
	int previousLayerNeuronsQuantity;
	double localError;
	
	public Neuron(int layerID){
		this.layerId = layerID;
	}
	
	public Neuron(int layerID, int previousLayerNeuronsQuantity){
		this.weightsPreviousLayer = new double[2][previousLayerNeuronsQuantity+1]; // 'cause the BIAS
		this.previousLayerNeuronsQuantity = 	previousLayerNeuronsQuantity;
		this.layerId = layerID;
		this.setAleatoryWeights();
		
	}
	void setAleatoryWeights(){
	//	Random random = new Random(getSemente());
		for(int i=0; i<this.previousLayerNeuronsQuantity; i++){
			this.weightsPreviousLayer[0][i]=this.weightsPreviousLayer[1][i] = Math.random();
		}
	}
	
	public String toString(){
		String string = "";
		for (int i=0; i<this.previousLayerNeuronsQuantity; i++){
			string = string + " " + weightsPreviousLayer[1][i];
		}
		return string;
	}
	
	void resetParamaters(){
		this.sensibility=0;
		this.net=0;
		this.fnet=0;
		this.f_derivate_net=0;
		

	}
	void setSensibility(double s){
		this.sensibility = s;
	}
	void setNet(double net){
		this.net = net;
	}
	
	void setFNet (double fnet){
		this.fnet = fnet;
	}
	void setFDerNet (Double f_der_net){
		this.f_derivate_net  = f_der_net;
	}
	
	double getSensibily (){
		return this.sensibility;
	}
	double getNet(){
		return net;
	}
	double getFNet(){
		return this.fnet;
	}
	double getFDerNet(){
		return this.f_derivate_net;
	}

}

public class MultilayerPerceptron {
	int layerQuantity;
	int neuronQuantityPerLayer[];
	double learningRate;
	int inputNumber;
	int outputNumber;
	int numberExamples;
	int rateTrainning;
	int quantityIteration;
	int fail;
	int verificationQuantity;
	//Neuron neurons[][];
	ArrayList<ArrayList> neurons = new ArrayList<ArrayList>();
	double [][]dataBaseTrainningTest;
	double [][]dataBaseVerificationTest;
	ArrayList errors = new ArrayList();
	ArrayList errorsValidation = new ArrayList();
	ArrayList errorsVerification = new ArrayList();
	ArrayList errorsVerification_EMA = new ArrayList();
	ArrayList errorsVerification_EPMA = new ArrayList();
	ArrayList errorsVerification_EP = new ArrayList();
	Arquivo fileVerification;
	int qtdProgramRun;
	double momentum;
	int windowSize;
	
	public MultilayerPerceptron(Arquivo fileVerification, int layerQuantity, int []neuronQuantityPerLayer, double learningRate, int inputNumber, int outputNumber, int numberExamples, int rateTrainning, int quantifyIteration, int verificationQuantity, int fail, int qtdProgramRun, double momentum, int windowSize){
		this.fileVerification = fileVerification;
		this.layerQuantity = layerQuantity;
		this.qtdProgramRun = qtdProgramRun;
		this.neuronQuantityPerLayer = neuronQuantityPerLayer;
		this.learningRate = learningRate;
		this.inputNumber = inputNumber;
		this.outputNumber = outputNumber;
		this.numberExamples = numberExamples;
		this.rateTrainning = rateTrainning;
		this.dataBaseTrainningTest = new double [numberExamples][inputNumber+outputNumber];
		this.dataBaseVerificationTest=  new double [verificationQuantity][inputNumber+outputNumber];
		this.quantityIteration = quantifyIteration;
		this.fail = fail;
		this.momentum = momentum;
		this.windowSize = windowSize;
		
		this.verificationQuantity = verificationQuantity;
		for (int i=0; i<layerQuantity; i++){
			neurons.add(new ArrayList<Neuron>());
		}
		
		
		for(int i=0; i<layerQuantity; i++){
			for (int j=0; j< this.neuronQuantityPerLayer[i] + 1; j++){ // +1 cause de BIAS
				Neuron aux;
				if (i==0){
					aux = new Neuron(i);
				}else{
					aux = new Neuron(i, this.neuronQuantityPerLayer[i-1]);
				}
				neurons.get(i).add(aux);
			}
				
		}
		
		if (windowSize== 0){
			readFile();
			readFileVerification();
		}else{
			readFile_Time_Forescast();
			readFileVerification_Time_Forescast();
		}
		
	}
	
	void readFile_Time_Forescast(){
		Arquivo file = new Arquivo("entrada_normalizada_energia.txt", "vazio.txt");
		for(int i=0; i<this.numberExamples - (this.windowSize-1); i++){
			if (i==0){
				for(int j=0; j<(this.inputNumber + this.outputNumber); j++){
					this.dataBaseTrainningTest[i][j] = file.readDouble();
				}
			}else{
				int j;
				for(j=0; j<(this.inputNumber + this.outputNumber)-1; j++){
					this.dataBaseTrainningTest[i][j] = this.dataBaseTrainningTest[i-1][j+1]; 
				}
				this.dataBaseTrainningTest[i][j] = file.readDouble();
				
			}

		}
		file.close();
		
	}
	void readFile (){
		Arquivo file = new Arquivo("inputNetwork.txt", "vazio.txt");
		for(int i=0; i<this.numberExamples; i++){
			for(int j=0; j<(this.inputNumber + this.outputNumber); j++){
				this.dataBaseTrainningTest[i][j] = file.readDouble();
			}
		}
		file.close();
		
	}
	void readFileVerification(){
		Arquivo file = new Arquivo("inputNetworkVerification.txt", "vazio.txt");
		for(int i=0; i<this.verificationQuantity; i++){
			for(int j=0; j<(this.inputNumber + this.outputNumber); j++){
				this.dataBaseVerificationTest[i][j] = file.readDouble();
			}
		}
		file.close();
	}
	
	void readFileVerification_Time_Forescast(){
		Arquivo file = new Arquivo("entrada_normalizada_energia_validacao.txt", "vazio.txt");
		for(int i=0; i<this.verificationQuantity - (this.windowSize-1); i++){
			if (i==0){
				for(int j=0; j<(this.inputNumber + this.outputNumber); j++){
					this.dataBaseVerificationTest[i][j] = file.readDouble();
				}
			}else{
				int j;
				for(j=0; j<(this.inputNumber + this.outputNumber)-1; j++){
					this.dataBaseVerificationTest[i][j] = this.dataBaseVerificationTest[i-1][j+1]; 
				}
				this.dataBaseVerificationTest[i][j] = file.readDouble();
			}
		}
		file.close();
		
	}
	void resetParamaterMLP(){
		for(int i=0; i<this.layerQuantity; i++){
			for (int j=0; j<this.neuronQuantityPerLayer[i]; j++){
				Neuron n = (Neuron)neurons.get(i).get(j);
				n.resetParamaters();
			}
		}
	}
	double sigmoidFunction (double net){
		//System.out.println("net: "+net);
		double result = 1/( 1 + Math.pow(Math.E,(-1*net)));
		//System.out.println("resultado da funcao sigmoidal: "+result);
		return result;
	}
	
	double der_sigmoidFunction(double x){
		return (x)*(1-x);
	}
	void forward(){
		double [] vetorPrevisao = new double[this.windowSize+1];
		double [] vetorPrevisaoValidacaoCruzada = new double[this.windowSize+1];
		double resultadoPrevisao = 0;
		double resultadoPrevisaoValidacaoCruzada = 0;
		
		boolean finishNetwork = true;
		int trainning = (this.numberExamples * this.rateTrainning) / 100;
		int validation = this.numberExamples - trainning;
		//System.out.println("numero de ex: "+numberExamples+" treinamento"+trainning+" validacao: "+validation);
		for (int in=0, valid=0, total=0, count=0; finishNetwork; in++, valid++, total++){
		//	System.out.println("aqui");
			resetParamaterMLP();
			if (in==trainning){
				in=0;
			}
			if (valid == this.numberExamples){
				valid=0;
			}
			
			
			if (in==0){
				for(int d=0; d<this.inputNumber; d++){
					vetorPrevisao[d] = this.dataBaseTrainningTest[in][d];
				}
			}else{
				for(int d=0; d<this.inputNumber; d++){
					vetorPrevisao[d] = this.dataBaseTrainningTest[in][d];
				}
				vetorPrevisao[this.inputNumber-1] = resultadoPrevisao;
			}
			
			// propagation
			for(int i=1; i<this.layerQuantity; i++){
				for(int j=0; j<this.neuronQuantityPerLayer[i]; j++){
					if (i==1){ // the inner product is between the input of the file and weights
						Neuron aux = (Neuron)neurons.get(i).get(j);
						int k;
						for(k=0; k<this.inputNumber; k++){
							aux.net += vetorPrevisao[k]* aux.weightsPreviousLayer[1][k];
						}
						// atention in the duplication code below
						aux.net += 1 * aux.weightsPreviousLayer[1][k]; // BIAS
						aux.fnet = sigmoidFunction(aux.net);
						
						aux.f_derivate_net = der_sigmoidFunction(aux.fnet);
						//System.out.println("fnet dos neuronios: "+aux.f_derivate_net+ " da camada: "+i);
					}else{
						Neuron aux = (Neuron)neurons.get(i).get(j);
						int k;
						for(k=0; k<aux.previousLayerNeuronsQuantity; k++){
							Neuron aux2 = (Neuron)neurons.get(i-1).get(k);
							aux.net += aux2.fnet* aux.weightsPreviousLayer[1][k];
						}
						
						aux.net += 1 * aux.weightsPreviousLayer[1][k]; // BIAS
						
						aux.fnet = sigmoidFunction(aux.net);
						aux.f_derivate_net = der_sigmoidFunction(aux.fnet);	
						//System.out.println("fnet dos neuronios: AQUI "+aux.f_derivate_net);
					}
					
				}
			}
			//verify the error of the network
			double localError=0;
			for(int i=0; i<this.outputNumber; i++ ){
				Neuron out = (Neuron)neurons.get(this.layerQuantity-1).get(i);
				resultadoPrevisao = out.fnet; /// resultado da previsao
				
				out.localError = (this.dataBaseTrainningTest[in][this.inputNumber+i] - out.fnet);
				localError += Math.abs(out.localError);
				//System.out.println("erro dentro: "+localError);
			//	System.out.println("Erro salvo: "+out.localError);
			}
			localError = (float)localError/(float)this.outputNumber;
			this.errors.add(localError);
			
			
			///FEEDFORWARD
			//calculus of the output neurons sensibility
			for(int i=0; i<this.outputNumber; i++ ){
				Neuron out = (Neuron)neurons.get(layerQuantity-1).get(i);
				out.sensibility = out.localError * out.f_derivate_net;
				//System.out.println("local error: "+out.localError+" sensibilidade saida: "+out.sensibility + "f der"+ out.f_derivate_net);
			}
		
			
			//calculus of sensibility hidden layer neurons
			for (int i = this.layerQuantity-2 ; i>0; i-- ){
				//will not go until zero, because input layer don't need sensibility
				for (int j=0; j< this.neuronQuantityPerLayer[i]; j++){
					Neuron n = (Neuron)neurons.get(i).get(j);
					for (int w=0; w< this.neuronQuantityPerLayer[i+1]; w++){
						Neuron aux = (Neuron)neurons.get(i+1).get(w);
						n.sensibility += aux.weightsPreviousLayer[1][j] * aux.sensibility;
					}
					// sensibility = f'(net)        *   SUM (w(i,j) * sensibility(i))
					n.sensibility = n.f_derivate_net *  n.sensibility ;
					//System.out.println("sensib hidd: "+n.sensibility);
				}
			}
			
			//update of the weights
			for (int i = this.layerQuantity-1 ; i>0; i-- ){
				//will not go until zero, because input layer doesn't need to update the weights
				for (int j=0; j< this.neuronQuantityPerLayer[i]; j++){
					Neuron n = (Neuron)neurons.get(i).get(j);
					int w;
					
					for(w=0; w < n.previousLayerNeuronsQuantity; w++){
						double tempTbefore = n.weightsPreviousLayer[0][w];
						n.weightsPreviousLayer[0][w]= n.weightsPreviousLayer[1][w];
						double momentumRate = this.momentum * (n.weightsPreviousLayer[1][w] - tempTbefore);
						if (i==1){ // camada de entrada
							n.weightsPreviousLayer[1][w] += this.learningRate * n.sensibility * vetorPrevisao[w] + momentumRate;
						}else{
							Neuron aux = (Neuron)neurons.get(i-1).get(w);
							n.weightsPreviousLayer[1][w] += this.learningRate * n.sensibility * aux.fnet + momentumRate;
						}
						//System.out.println("antes de mudar: "+n.weightsPreviousLayer[w]);
						//System.out.println("learning rate: "+ learningRate+ "sensib: "+n.sensibility+" fnet: "+aux.fnet+" camada: "+ i);
						//System.out.println("mudando peso: "+n.weightsPreviousLayer[w]);
					}
					double tempTbefore = n.weightsPreviousLayer[0][w];
					n.weightsPreviousLayer[0][w]= n.weightsPreviousLayer[1][w];
					double momentumRate = this.momentum * (n.weightsPreviousLayer[1][w] - tempTbefore);
					n.weightsPreviousLayer[1][w] += this.learningRate * n.sensibility * 1 + momentumRate;
				}
			}
			
			//validation
			resetParamaterMLP();
			if (in==0){
				for(int d=0; d<this.inputNumber; d++){
					vetorPrevisaoValidacaoCruzada[d] = this.dataBaseTrainningTest[valid][d];
				}
			}else{
				for(int d=0; d<this.inputNumber; d++){
					vetorPrevisaoValidacaoCruzada[d] = this.dataBaseTrainningTest[valid][d];
				}
				vetorPrevisaoValidacaoCruzada[this.inputNumber-1] = resultadoPrevisao;
			}
			for(int i=1; i<this.layerQuantity; i++){
				for(int j=0; j<this.neuronQuantityPerLayer[i]; j++){
					if (i==1){ // the inner product is between the layer input and weights
						Neuron aux = (Neuron)neurons.get(i).get(j);
						int k;
						for(k=0; k<this.inputNumber; k++){
							aux.net += vetorPrevisaoValidacaoCruzada[k]* aux.weightsPreviousLayer[1][k];
						}
						aux.net += 1 * aux.weightsPreviousLayer[1][k];
						
						aux.fnet = sigmoidFunction(aux.net);
						aux.f_derivate_net = der_sigmoidFunction(aux.fnet);
					}else{
						Neuron aux = (Neuron)neurons.get(i).get(j);
						int k;
						for(k=0; k<aux.previousLayerNeuronsQuantity; k++){
							Neuron aux2 = (Neuron)neurons.get(i-1).get(k);
							aux.net += aux2.fnet* aux.weightsPreviousLayer[1][k];
						}
						aux.net += 1 * aux.weightsPreviousLayer[1][k];
						aux.fnet = sigmoidFunction(aux.net);
						aux.f_derivate_net = der_sigmoidFunction(aux.fnet);						
					}
					
				}
			}
			//verify the error of the network
			double last=99999999;
			if (this.errorsValidation.size() > 0){
				last= (Double) this.errorsValidation.get(this.errorsValidation.size()-1);
			}
			double localErrorValidation=0;
			for(int i=0; i<this.outputNumber; i++ ){
				Neuron out = (Neuron)neurons.get(this.layerQuantity-1).get(i);
				resultadoPrevisaoValidacaoCruzada = out.fnet;
				localErrorValidation += Math.abs(this.dataBaseTrainningTest[valid][this.inputNumber+i] - out.fnet);
			}
			localErrorValidation = localErrorValidation/this.outputNumber;
			
			
			/*
			 TODO: TO VERIFY IT
			*/
			
			
			localErrorValidation = Math.abs(localErrorValidation);
			last = Math.abs(last);
			
			this.errorsValidation.add(localErrorValidation);
			
			if (localErrorValidation > last){
			//	System.out.println("SAIR1   " + last + " "+localErrorValidation);
				count++;
				if(count>this.fail){
					System.out.println("SAIR POR FAIL");	
					break;
				}
			}else{
				//TO VERIFY THIS
				if (count<this.fail/2){
					count=0;
				}
			}
			
			if(total >this.quantityIteration){
				System.out.println("SAIR POR QUANTIDADE DE ITERACAO");
				break;
			}
		//		System.out.println(this.neurons);
			
			
			
			
		}
		
		
	}
	
	void verification(String nomeArq){
		double [] vetorPrevisao = new double[this.windowSize+1];
			double resultadoPrevisao = 0;
			
		for(int a=0; a<this.verificationQuantity; a++){
			
			if (a==0){
				for(int d=0; d<this.inputNumber; d++){
					vetorPrevisao[d] = this.dataBaseTrainningTest[a][d];
				}
			}else{
				for(int d=0; d<this.inputNumber; d++){
					vetorPrevisao[d] = this.dataBaseTrainningTest[a][d];
				}
				vetorPrevisao[this.inputNumber-1] = resultadoPrevisao;
			}
			
			resetParamaterMLP();
			for(int i=1; i<this.layerQuantity; i++){
				for(int j=0; j<this.neuronQuantityPerLayer[i]; j++){
					if (i==1){ // the inner product is between the layer input and weights
						Neuron aux = (Neuron)neurons.get(i).get(j);
						int k;
						for(k=0; k<this.inputNumber; k++){
							aux.net += vetorPrevisao[k]* aux.weightsPreviousLayer[1][k];
						}
						aux.net += 1 * aux.weightsPreviousLayer[1][k];
						
						aux.fnet = sigmoidFunction(aux.net);
						aux.f_derivate_net = der_sigmoidFunction(aux.fnet);
					}else{
						Neuron aux = (Neuron)neurons.get(i).get(j);
						int k;
						for(k=0; k<aux.previousLayerNeuronsQuantity; k++){
							Neuron aux2 = (Neuron)neurons.get(i-1).get(k);
							aux.net += aux2.fnet* aux.weightsPreviousLayer[1][k];
						}
						aux.net += 1 * aux.weightsPreviousLayer[1][k];
						aux.fnet = sigmoidFunction(aux.net);
						aux.f_derivate_net = der_sigmoidFunction(aux.fnet);						
					}
					
				}
			}
			//verify the error of the network
			
			double localErrorVerification=0;
			double error_EPMA=0;
			double error_EP=0;
			
			for(int i=0; i<this.outputNumber; i++ ){
				Neuron out = (Neuron)neurons.get(this.layerQuantity-1).get(i);
				resultadoPrevisao = out.fnet;
				double dif  = Math.abs(this.dataBaseVerificationTest[a][this.inputNumber+i] - out.fnet);
				localErrorVerification += dif;
				error_EPMA += (dif/this.dataBaseVerificationTest[a][this.inputNumber+i]);
				
			}
			localErrorVerification = localErrorVerification/this.outputNumber;
			
			/*
			 TODO: TO VERIFY IT
			*/
			
			localErrorVerification = Math.abs(localErrorVerification);
			
			this.errorsVerification.add(localErrorVerification);
			
			this.errorsVerification_EMA.add(localErrorVerification);
			this.errorsVerification_EPMA.add(error_EPMA);
			this.errorsVerification_EP.add(Math.pow(localErrorVerification,2));
			
			
			
		}
		
		String arq = "validacao_"+nomeArq;
		
		double v=0;
		Arquivo fileValidationResults = new Arquivo("vazio.txt", arq);
		fileValidationResults.print("qtde: "+this.verificationQuantity+"\n");
		fileValidationResults.print("tamanho: "+errorsVerification_EMA.size()+"\n");
		///imprimir resultados da verificação
		for (int i=0; i<this.errorsVerification_EMA.size(); i++){ 		
			v += (double) (Double) this.errorsVerification_EMA.get(i);
			fileValidationResults.print(errorsVerification_EMA.get(i)+"\n");
		}
		int tam = errorsVerification_EMA.size();
		float media = (float) (v/tam);
		
		fileValidationResults.print("\n\n"+media);
	
		fileValidationResults.close();
	}
	
	double finishSaveFile(){
		
		
		this.fileVerification.println(this.layerQuantity);
		this.fileVerification.println("Taxa de aprendizagem: "+this.learningRate);
		this.fileVerification.println("Quantidade Iteracao: "+this.quantityIteration);
		this.fileVerification.println("Quantos neuronios em cada camada: ");
		
		/*
		 qtd neurons of input layer
		 qtde neurons for each hidden layer
		 qtde neurons output layer
		 */
		
		
		for(int i=0; i<this.neuronQuantityPerLayer.length; i++){
			fileVerification.println(this.neuronQuantityPerLayer[i]);
		}
		/*
		 for each weight for each neuron
		 starting of the second layer (the first doesnt have weights)
		 */
		
	//	for(int i=1; i<this.layerQuantity; i++){
		//	for(int j=0; j<this.neuronQuantityPerLayer[i]; j++){
			//	Neuron n = (Neuron)this.neurons.get(i).get(j);
				//for(int k=0; k< n.previousLayerNeuronsQuantity; k++){
				//	out.println(n.weightsPreviousLayer[k]);
				//}
			//}
		//}
		String arq = "analise_erros_"+learningRate+"_";
		for(int i=0; i<this.layerQuantity; i++){
			arq += this.neuronQuantityPerLayer[i]+"_";
		}
		arq += this.neuronQuantityPerLayer[1]+"_"+this.qtdProgramRun;
		
		Arquivo fileVerificationAUX2 = new Arquivo("vazio.txt", arq);
		
		 //Errors of the Training
		 
		fileVerificationAUX2.println("\n\nTraining Errors ("+this.errors.size()+")");
		
		for (int i=0; i<this.errors.size(); i++){
			fileVerificationAUX2.println((Double)this.errors.get(i));
		}
		
		return (Double) (this.errors.get(this.errors.size() -1));
		
		 //Errors of the Validation
		/*
		fileVerificationAUX2.println("\n\nValidation Errors ("+this.errorsValidation.size()+")");
		for (int i=0; i<this.errorsValidation.size(); i++){
			fileVerificationAUX2.println((Double)this.errorsValidation.get(i));
		}
		*/
		/*
		 Errors of the Verification - EMA
		 */
		
		/*
		double error_EMA =0;
		double error_EPMA =0;
		double error_EP =0;
		//out.println("\n\n Verification Errors - EMA ("+this.errorsVerification.size()+")");
		for (int i=0; i<this.errorsVerification.size(); i++){
			//out.println((Double)this.errorsVerification.get(i));
			error_EMA += (Double)this.errorsVerification.get(i);
		}
		*/
		/*
		 Errors of the Verification - EPMA
		 */
		//out.println("\n\n Verification Errors - EPMA ("+this.errorsVerification_EPMA.size()+")");
		/*
		for (int i=0; i<this.errorsVerification_EPMA.size(); i++){
			//out.println((Double)this.errorsVerification_EPMA.get(i));
			error_EPMA += (Double)this.errorsVerification.get(i);
		}
		*/
		/*
		 Errors of the Verification - EP
		 */
		//out.println("\n\n Verification Errors - EP ("+this.errorsVerification_EP.size()+")");
		/*
		for (int i=0; i<this.errorsVerification_EP.size(); i++){
			//out.println((Double)this.errorsVerification_EP.get(i));
			error_EP += (Double)this.errorsVerification.get(i);
		}
		
		error_EMA = error_EMA / this.verificationQuantity;
		error_EPMA = 100 * error_EPMA / this.verificationQuantity;
		error_EP = Math.sqrt(error_EP /this.verificationQuantity);
		
		fileVerification.println("\nEMA: "+error_EMA);
		fileVerification.println("EPMA: "+error_EPMA);
		fileVerification.println("EP: "+error_EP+"\n");
		
		this.errors = new ArrayList();
		this.errorsValidation = new ArrayList();
		this.errorsVerification = new ArrayList();
		this.errorsVerification_EMA = new ArrayList();
		this.errorsVerification_EPMA = new ArrayList();
		this.errorsVerification_EP = new ArrayList();
		
		return error_EPMA;
		*/
	}
	
	//Neuron n = new Neuron(2);

	/**
	 * @param args
	 */
	public static void main(String[] args) {
		
		
		int qtdProgramRun = 20;
		int []neuronsPerLayer = {1,3,1};
		//MultilayerPerceptron mlp = new MultilayerPerceptron(int layerQuantity=3,  neuronsPerLayer, learningRate= 0.3, inputNumber= 10, outputNumber = 1, numberExamples = 100, rateTrainning = 50, quantityIteration = 50, fail = 10);
		Arquivo fileVerification = new Arquivo("inputNetworkVerification.txt", "outputNetwork.txt");
		double learningRate=0.1;
		neuronsPerLayer[1] =10;
		qtdeIteracao=5000;
				
					double retorno =0;
					double retornoA =0;
					double maiorM =0;
					double menorM = 999999999;

			Arquivo fileVerificationAUX = new Arquivo("vazio.txt", "erros_"+learningRate+"_"+neuronsPerLayer[1]+"_"+qtdeIteracao);
			for(int i=0; i< qtdProgramRun; i++ ){
				int numberExamples = 100;
				int rateTrainning = 80;
				int numberVerification = 20;
				int fail = 100;
				double momentum = 0.3;
				int windowSize = 2;
				
				MultilayerPerceptron mlp = new MultilayerPerceptron(fileVerification, 3, neuronsPerLayer, learningRate, neuronsPerLayer[0], neuronsPerLayer[neuronsPerLayer.length -1], numberExamples, rateTrainning, qtdeIteracao, numberVerification, fail, qtdProgramRun, momentum, windowSize);
				mlp.forward();
				//System.out.println(mlp.neurons);
				mlp.verification("erros_"+learningRate+"_"+neuronsPerLayer[1]+"_"+qtdeIteracao+"_"+i);
				
				retornoA = mlp.finishSaveFile();
				retorno += retornoA;
				//fileVerificationAUX.println(retornoA);
				if (retornoA > maiorM){
					maiorM = retornoA;
				}
				if (retornoA < menorM){
					menorM = retornoA; 
				}
				
			}
			
			fileVerificationAUX.println(retorno/qtdProgramRun);
			fileVerificationAUX.println(maiorM);
			fileVerificationAUX.println(menorM);
			
					
				}
			}
				
		
		
		fileVerification.close();
		
	}

}
